{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento con Redes Neuronales para Detección de Phishing\n",
    "\n",
    "Este notebook documenta el experimento de implementación de redes neuronales para la detección de URLs de phishing, comparando su rendimiento con el modelo RandomForest existente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "La detección de phishing es un problema crítico de seguridad informática. En este experimento, implementamos y evaluamos diferentes arquitecturas de redes neuronales (MLP y CNN) utilizando PyTorch, y comparamos su rendimiento con el modelo RandomForest que ya se había implementado anteriormente.\n",
    "\n",
    "### Objetivos del experimento:\n",
    "\n",
    "1. Implementar modelos de redes neuronales para la detección de phishing\n",
    "2. Evaluar y comparar el rendimiento de diferentes arquitecturas\n",
    "3. Determinar si las redes neuronales ofrecen ventajas sobre los modelos tradicionales de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metodología\n",
    "\n",
    "### 2.1 Arquitecturas implementadas\n",
    "\n",
    "#### Red Neuronal MLP (Perceptrón Multicapa)\n",
    "\n",
    "- **Arquitectura**: 4 capas densamente conectadas (input → 128 → 64 → 32 → 1)\n",
    "- **Activaciones**: ReLU en capas ocultas, Sigmoid en la capa de salida\n",
    "- **Regularización**: Dropout (0.2) para prevenir sobreajuste\n",
    "- **Optimizador**: Adam con tasa de aprendizaje de 0.001\n",
    "- **Función de pérdida**: Binary Cross Entropy (BCE)\n",
    "\n",
    "#### Red Neuronal CNN (Red Neuronal Convolucional)\n",
    "\n",
    "- **Arquitectura**:\n",
    "  - Capa convolucional 1: 1 → 16 filtros, kernel 3x3, padding 1, ReLU, MaxPooling 2x2\n",
    "  - Capa convolucional 2: 16 → 32 filtros, kernel 3x3, padding 1, ReLU, MaxPooling 2x2\n",
    "  - Capas densas: Flatten → 128 → 64 → 1\n",
    "- **Activaciones**: ReLU en capas ocultas, Sigmoid en la capa de salida\n",
    "- **Regularización**: Dropout (0.5 y 0.3) para prevenir sobreajuste\n",
    "- **Optimizador**: Adam con tasa de aprendizaje de 0.001\n",
    "- **Función de pérdida**: Binary Cross Entropy (BCE)\n",
    "\n",
    "### 2.2 Preprocesamiento de datos\n",
    "\n",
    "- Eliminación de columnas no numéricas\n",
    "- Normalización de características con StandardScaler\n",
    "- División en conjuntos de entrenamiento (70%) y prueba (30%)\n",
    "- Para CNN: Reorganización de características en formato 2D (matriz cuadrada)\n",
    "\n",
    "### 2.3 Entrenamiento\n",
    "\n",
    "- Épocas: 10\n",
    "- Tamaño de batch: 64\n",
    "- Monitoreo de pérdida durante el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resultados\n",
    "\n",
    "### 3.1 Comparación de métricas\n",
    "\n",
    "La siguiente tabla muestra una comparación de las métricas clave para los tres modelos:\n",
    "\n",
    "| Modelo | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Avg Precision |\n",
    "|--------|----------|-----------|--------|----------|---------|---------------|\n",
    "| RandomForest | ~1.00 | ~1.00 | ~1.00 | ~1.00 | ~1.00 | ~1.00 |\n",
    "| MLP | 0.98-0.99 | 0.98-0.99 | 0.98-0.99 | 0.98-0.99 | 0.99+ | 0.99+ |\n",
    "| CNN | 0.97-0.99 | 0.97-0.99 | 0.97-0.99 | 0.97-0.99 | 0.99+ | 0.99+ |\n",
    "\n",
    "*Nota: Los valores exactos pueden variar ligeramente en cada ejecución.*\n",
    "\n",
    "### 3.2 Visualizaciones\n",
    "\n",
    "Se generaron las siguientes visualizaciones para comparar los modelos:\n",
    "\n",
    "- **Curvas de pérdida**: Muestran la convergencia de los modelos neuronales durante el entrenamiento\n",
    "- **Matrices de confusión**: Visualizan los verdaderos/falsos positivos/negativos para cada modelo\n",
    "- **Curvas ROC**: Comparan la capacidad discriminativa de los modelos\n",
    "- **Curvas Precision-Recall**: Evalúan el equilibrio entre precisión y exhaustividad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis y Discusión\n",
    "\n",
    "### 4.1 Rendimiento comparativo\n",
    "\n",
    "- **RandomForest**: Muestra un rendimiento excepcional, cercano a la perfección en todas las métricas. Esto podría indicar que las características del dataset son altamente discriminativas o que existe algún sesgo en los datos.\n",
    "\n",
    "- **MLP**: Logra un rendimiento muy alto, aunque ligeramente inferior al RandomForest. La arquitectura de capas densas captura eficientemente las relaciones entre las características.\n",
    "\n",
    "- **CNN**: También alcanza un rendimiento alto, pero con mayor variabilidad. La transformación de las características en formato 2D podría no ser óptima para este problema específico, ya que las características originales no tienen una estructura espacial inherente.\n",
    "\n",
    "### 4.2 Ventajas y desventajas\n",
    "\n",
    "#### RandomForest:\n",
    "- **Ventajas**: Mayor interpretabilidad, entrenamiento más rápido, excelente rendimiento\n",
    "- **Desventajas**: Menos flexible para capturar patrones complejos en datos muy grandes\n",
    "\n",
    "#### Redes Neuronales (MLP/CNN):\n",
    "- **Ventajas**: Mayor capacidad para modelar relaciones complejas, adaptabilidad a diferentes tipos de datos\n",
    "- **Desventajas**: Mayor tiempo de entrenamiento, más hiperparámetros para ajustar, menor interpretabilidad\n",
    "\n",
    "### 4.3 Consideraciones sobre el dataset\n",
    "\n",
    "El rendimiento excepcionalmente alto de todos los modelos sugiere que:\n",
    "\n",
    "1. Las características del dataset son altamente discriminativas para la tarea de detección de phishing\n",
    "2. Podría existir algún sesgo o filtración de información entre los conjuntos de entrenamiento y prueba\n",
    "3. El problema de detección de phishing, tal como está representado en este dataset, podría ser relativamente sencillo de resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones\n",
    "\n",
    "1. **Efectividad de los modelos**: Todos los modelos evaluados (RandomForest, MLP y CNN) muestran un rendimiento excepcional en la detección de URLs de phishing, con métricas cercanas a la perfección.\n",
    "\n",
    "2. **Comparación de arquitecturas**: Para este problema específico, el modelo RandomForest ofrece la mejor combinación de rendimiento y eficiencia computacional. Sin embargo, las redes neuronales también demuestran ser altamente efectivas.\n",
    "\n",
    "3. **Aplicabilidad práctica**: La implementación de estos modelos en sistemas de seguridad podría proporcionar una detección altamente precisa de intentos de phishing, contribuyendo significativamente a la protección de usuarios.\n",
    "\n",
    "4. **Trabajo futuro**: Se recomienda explorar:\n",
    "   - Validación cruzada más exhaustiva para confirmar la robustez de los resultados\n",
    "   - Pruebas con datasets más diversos y desafiantes\n",
    "   - Arquitecturas híbridas que combinen las fortalezas de los diferentes enfoques\n",
    "   - Técnicas de interpretabilidad para entender mejor las decisiones de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Referencias\n",
    "\n",
    "- Dataset: PhiUSIIL Phishing URL Dataset\n",
    "- PyTorch: https://pytorch.org/docs/stable/index.html\n",
    "- Scikit-learn: https://scikit-learn.org/stable/\n",
    "- Análisis previo: EDA_metricas_completo.ipynb y metricas_avanzadas.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
