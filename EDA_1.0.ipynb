{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AaaLSb07cjB",
        "outputId": "4d82fe6d-27b7-497a-c818-bc29ee8ad252"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis de URLs de Phishing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "zswvqG_bNFGg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración para visualizaciones\n",
        "plt.style.use('ggplot')\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "UGy6WEmxNL0V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargar el dataset\n",
        "print(\"Cargando el dataset...\")\n",
        "try:\n",
        "    # Intentar cargar el dataset (puede requerir ajustes en el delimitador)\n",
        "    #df = pd.read_csv('PhiUSIIL_Phishing_URL_Dataset.csv')\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/juancmacias/datas/main/DataSet/PhiUSIIL_Phishing_URL_Dataset.csv\")\n",
        "    print(f\"Dataset cargado correctamente. Dimensiones: {df.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar el dataset: {e}\")\n",
        "    # Intentar con diferentes delimitadores\n",
        "    try:\n",
        "        df = pd.read_csv('PhiUSIIL_Phishing_URL_Dataset.csv', delimiter=',')\n",
        "        print(f\"Dataset cargado con delimitador ','. Dimensiones: {df.shape}\")\n",
        "    except:\n",
        "        try:\n",
        "            df = pd.read_csv('PhiUSIIL_Phishing_URL_Dataset.csv', delimiter=';')\n",
        "            print(f\"Dataset cargado con delimitador ';'. Dimensiones: {df.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"No se pudo cargar el dataset: {e}\")\n",
        "            exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nRaX68YNO2N",
        "outputId": "38ad75e4-6a0d-492f-da67-e78c6e4a11f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando el dataset...\n",
            "Dataset cargado correctamente. Dimensiones: (235795, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Análisis Exploratorio de Datos (EDA)\n",
        "print(\"\\n--- ANÁLISIS EXPLORATORIO DE DATOS ---\")\n",
        "\n",
        "# Información básica del dataset\n",
        "print(\"\\nInformación básica del dataset:\")\n",
        "print(f\"Número de filas: {df.shape[0]}\")\n",
        "print(f\"Número de columnas: {df.shape[1]}\")\n",
        "\n",
        "# Verificar si hay una columna de etiquetas (phishing o legítimo)\n",
        "print(\"\\nColumnas en el dataset:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Asumiendo que la última columna es la etiqueta\n",
        "target_column = df.columns[-1]\n",
        "print(f\"\\nColumna objetivo (asumida): {target_column}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CJWRNc9OAoR",
        "outputId": "0337245c-efba-4ec3-8c52-0b28ada62091"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ANÁLISIS EXPLORATORIO DE DATOS ---\n",
            "\n",
            "Información básica del dataset:\n",
            "Número de filas: 235795\n",
            "Número de columnas: 56\n",
            "\n",
            "Columnas en el dataset:\n",
            "['FILENAME', 'URL', 'URLLength', 'Domain', 'DomainLength', 'IsDomainIP', 'TLD', 'URLSimilarityIndex', 'CharContinuationRate', 'TLDLegitimateProb', 'URLCharProb', 'TLDLength', 'NoOfSubDomain', 'HasObfuscation', 'NoOfObfuscatedChar', 'ObfuscationRatio', 'NoOfLettersInURL', 'LetterRatioInURL', 'NoOfDegitsInURL', 'DegitRatioInURL', 'NoOfEqualsInURL', 'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'IsHTTPS', 'LineOfCode', 'LargestLineLength', 'HasTitle', 'Title', 'DomainTitleMatchScore', 'URLTitleMatchScore', 'HasFavicon', 'Robots', 'IsResponsive', 'NoOfURLRedirect', 'NoOfSelfRedirect', 'HasDescription', 'NoOfPopup', 'NoOfiFrame', 'HasExternalFormSubmit', 'HasSocialNet', 'HasSubmitButton', 'HasHiddenFields', 'HasPasswordField', 'Bank', 'Pay', 'Crypto', 'HasCopyrightInfo', 'NoOfImage', 'NoOfCSS', 'NoOfJS', 'NoOfSelfRef', 'NoOfEmptyRef', 'NoOfExternalRef', 'label']\n",
            "\n",
            "Columna objetivo (asumida): label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas descriptivas\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmkQuyVsOOcq",
        "outputId": "61c599b8-c6ca-4a9c-ac21-3c11c8765b54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas descriptivas:\n",
            "           URLLength   DomainLength     IsDomainIP  URLSimilarityIndex  \\\n",
            "count  235795.000000  235795.000000  235795.000000       235795.000000   \n",
            "mean       34.573095      21.470396       0.002706           78.430778   \n",
            "std        41.314153       9.150793       0.051946           28.976055   \n",
            "min        13.000000       4.000000       0.000000            0.155574   \n",
            "25%        23.000000      16.000000       0.000000           57.024793   \n",
            "50%        27.000000      20.000000       0.000000          100.000000   \n",
            "75%        34.000000      24.000000       0.000000          100.000000   \n",
            "max      6097.000000     110.000000       1.000000          100.000000   \n",
            "\n",
            "       CharContinuationRate  TLDLegitimateProb    URLCharProb      TLDLength  \\\n",
            "count         235795.000000      235795.000000  235795.000000  235795.000000   \n",
            "mean               0.845508           0.260423       0.055747       2.764456   \n",
            "std                0.216632           0.251628       0.010587       0.599739   \n",
            "min                0.000000           0.000000       0.001083       2.000000   \n",
            "25%                0.680000           0.005977       0.050747       2.000000   \n",
            "50%                1.000000           0.079963       0.057970       3.000000   \n",
            "75%                1.000000           0.522907       0.062875       3.000000   \n",
            "max                1.000000           0.522907       0.090824      13.000000   \n",
            "\n",
            "       NoOfSubDomain  HasObfuscation  ...            Pay         Crypto  \\\n",
            "count  235795.000000   235795.000000  ...  235795.000000  235795.000000   \n",
            "mean        1.164758        0.002057  ...       0.237007       0.023474   \n",
            "std         0.600969        0.045306  ...       0.425247       0.151403   \n",
            "min         0.000000        0.000000  ...       0.000000       0.000000   \n",
            "25%         1.000000        0.000000  ...       0.000000       0.000000   \n",
            "50%         1.000000        0.000000  ...       0.000000       0.000000   \n",
            "75%         1.000000        0.000000  ...       0.000000       0.000000   \n",
            "max        10.000000        1.000000  ...       1.000000       1.000000   \n",
            "\n",
            "       HasCopyrightInfo      NoOfImage        NoOfCSS         NoOfJS  \\\n",
            "count     235795.000000  235795.000000  235795.000000  235795.000000   \n",
            "mean           0.486775      26.075689       6.333111      10.522305   \n",
            "std            0.499826      79.411815      74.866296      22.312192   \n",
            "min            0.000000       0.000000       0.000000       0.000000   \n",
            "25%            0.000000       0.000000       0.000000       0.000000   \n",
            "50%            0.000000       8.000000       2.000000       6.000000   \n",
            "75%            1.000000      29.000000       8.000000      15.000000   \n",
            "max            1.000000    8956.000000   35820.000000    6957.000000   \n",
            "\n",
            "         NoOfSelfRef   NoOfEmptyRef  NoOfExternalRef          label  \n",
            "count  235795.000000  235795.000000    235795.000000  235795.000000  \n",
            "mean       65.071113       2.377629        49.262516       0.571895  \n",
            "std       176.687539      17.641097       161.027430       0.494805  \n",
            "min         0.000000       0.000000         0.000000       0.000000  \n",
            "25%         0.000000       0.000000         1.000000       0.000000  \n",
            "50%        12.000000       0.000000        10.000000       1.000000  \n",
            "75%        88.000000       1.000000        57.000000       1.000000  \n",
            "max     27397.000000    4887.000000     27516.000000       1.000000  \n",
            "\n",
            "[8 rows x 51 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U4MzFoPOUMC",
        "outputId": "f247754e-556d-4493-cfa4-870df7bec348"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valores nulos por columna:\n",
            "FILENAME                      0\n",
            "URL                           0\n",
            "URLLength                     0\n",
            "Domain                        0\n",
            "DomainLength                  0\n",
            "IsDomainIP                    0\n",
            "TLD                           0\n",
            "URLSimilarityIndex            0\n",
            "CharContinuationRate          0\n",
            "TLDLegitimateProb             0\n",
            "URLCharProb                   0\n",
            "TLDLength                     0\n",
            "NoOfSubDomain                 0\n",
            "HasObfuscation                0\n",
            "NoOfObfuscatedChar            0\n",
            "ObfuscationRatio              0\n",
            "NoOfLettersInURL              0\n",
            "LetterRatioInURL              0\n",
            "NoOfDegitsInURL               0\n",
            "DegitRatioInURL               0\n",
            "NoOfEqualsInURL               0\n",
            "NoOfQMarkInURL                0\n",
            "NoOfAmpersandInURL            0\n",
            "NoOfOtherSpecialCharsInURL    0\n",
            "SpacialCharRatioInURL         0\n",
            "IsHTTPS                       0\n",
            "LineOfCode                    0\n",
            "LargestLineLength             0\n",
            "HasTitle                      0\n",
            "Title                         0\n",
            "DomainTitleMatchScore         0\n",
            "URLTitleMatchScore            0\n",
            "HasFavicon                    0\n",
            "Robots                        0\n",
            "IsResponsive                  0\n",
            "NoOfURLRedirect               0\n",
            "NoOfSelfRedirect              0\n",
            "HasDescription                0\n",
            "NoOfPopup                     0\n",
            "NoOfiFrame                    0\n",
            "HasExternalFormSubmit         0\n",
            "HasSocialNet                  0\n",
            "HasSubmitButton               0\n",
            "HasHiddenFields               0\n",
            "HasPasswordField              0\n",
            "Bank                          0\n",
            "Pay                           0\n",
            "Crypto                        0\n",
            "HasCopyrightInfo              0\n",
            "NoOfImage                     0\n",
            "NoOfCSS                       0\n",
            "NoOfJS                        0\n",
            "NoOfSelfRef                   0\n",
            "NoOfEmptyRef                  0\n",
            "NoOfExternalRef               0\n",
            "label                         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribución de la variable objetivo (si existe)\n",
        "if target_column in df.columns:\n",
        "    print(f\"\\nDistribución de la variable objetivo '{target_column}':\")\n",
        "    print(df[target_column].value_counts())\n",
        "    print(f\"Porcentaje: {df[target_column].value_counts(normalize=True) * 100}\")\n",
        "\n",
        "    # Visualización de la distribución de clases\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x=target_column, data=df)\n",
        "    plt.title('Distribución de URLs de Phishing vs Legítimas')\n",
        "    plt.savefig('distribucion_clases.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnnf8CMOOZ2L",
        "outputId": "6d88c8e7-202a-4063-a1d2-15b245e9a087"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribución de la variable objetivo 'label':\n",
            "label\n",
            "1    134850\n",
            "0    100945\n",
            "Name: count, dtype: int64\n",
            "Porcentaje: label\n",
            "1    57.189508\n",
            "0    42.810492\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de correlación\n",
        "print(\"\\nCalculando matriz de correlación...\")\n",
        "try:\n",
        "    # Seleccionar solo columnas numéricas\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Calcular y visualizar la matriz de correlación\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    mask = np.triu(correlation_matrix)\n",
        "    sns.heatmap(correlation_matrix, annot=False, mask=mask, cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title('Matriz de Correlación de Características')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('matriz_correlacion.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Identificar características altamente correlacionadas\n",
        "    high_corr_features = []\n",
        "    corr_threshold = 0.8\n",
        "\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(correlation_matrix.iloc[i, j]) > corr_threshold:\n",
        "                high_corr_features.append((correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]))\n",
        "\n",
        "    if high_corr_features:\n",
        "        print(\"\\nCaracterísticas altamente correlacionadas (|corr| > 0.8):\")\n",
        "        for feat1, feat2, corr in high_corr_features:\n",
        "            print(f\"{feat1} - {feat2}: {corr:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nNo se encontraron características altamente correlacionadas (|corr| > 0.8)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al calcular la matriz de correlación: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quaQRWRjOiC_",
        "outputId": "735cd884-346a-4b0a-fe6a-b3467ab17bce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculando matriz de correlación...\n",
            "\n",
            "Características altamente correlacionadas (|corr| > 0.8):\n",
            "NoOfLettersInURL - URLLength: 0.9560\n",
            "NoOfDegitsInURL - URLLength: 0.8358\n",
            "NoOfEqualsInURL - NoOfDegitsInURL: 0.8060\n",
            "URLTitleMatchScore - DomainTitleMatchScore: 0.9610\n",
            "label - URLSimilarityIndex: 0.8604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogramas de características numéricas\n",
        "try:\n",
        "    numeric_columns = numeric_df.columns[:10]  # Limitar a 10 columnas para no generar demasiados gráficos\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    for i, column in enumerate(numeric_columns, 1):\n",
        "        plt.subplot(3, 4, i)\n",
        "        sns.histplot(df[column], kde=True)\n",
        "        plt.title(f'Distribución de {column}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('histogramas_caracteristicas.png')\n",
        "    plt.close()\n",
        "except Exception as e:\n",
        "    print(f\"Error al generar histogramas: {e}\")"
      ],
      "metadata": {
        "id": "dQ03n6b_Nc92"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preparación de datos para modelado\n",
        "print(\"\\n--- PREPARACIÓN DE DATOS PARA MODELADO ---\")\n",
        "\n",
        "# Separar características y variable objetivo\n",
        "#if target_column in df.columns:\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "# Eliminar columnas no numéricas o irrelevantes para el modelado\n",
        "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "if non_numeric_cols:\n",
        "    print(f\"\\nEliminando columnas no numéricas: {non_numeric_cols}\")\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "# Verificar si hay valores infinitos y reemplazarlos\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Imputar valores nulos con la media\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(f\"\\nImputando {X.isnull().sum().sum()} valores nulos con la media\")\n",
        "    X = X.fillna(X.mean())\n",
        "\n",
        "# Normalizar características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# División en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
        "print(f\"Conjunto de prueba: {X_test.shape[0]} muestras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQfaATaxR2i0",
        "outputId": "14db5158-9cc6-4f5d-a864-3a6cf47211e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PREPARACIÓN DE DATOS PARA MODELADO ---\n",
            "\n",
            "Eliminando columnas no numéricas: ['FILENAME', 'URL', 'Domain', 'TLD', 'Title']\n",
            "\n",
            "Conjunto de entrenamiento: 188636 muestras\n",
            "Conjunto de prueba: 47159 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Modelado y Evaluación\n",
        "print(\"\\n--- MODELADO Y EVALUACIÓN ---\")\n",
        "\n",
        "# Lista para almacenar resultados de modelos\n",
        "models_results = []\n",
        "\n",
        "# Función para entrenar y evaluar modelos\n",
        "def train_evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    # Entrenamiento\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Guardar resultados\n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "    # Validación cruzada\n",
        "    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
        "    results['cv_mean'] = cv_scores.mean()\n",
        "    results['cv_std'] = cv_scores.std()\n",
        "\n",
        "    # Calcular overfitting\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    results['train_accuracy'] = train_accuracy\n",
        "    results['overfitting'] = train_accuracy - accuracy\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0wPRd4DSAxV",
        "outputId": "2ac141fd-c353-4d99-ab07-9b0a3be9eb57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- MODELADO Y EVALUACIÓN ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo 1: Random Forest\n",
        "print(\"\\nEntrenando Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_results = train_evaluate_model(rf_model, \"Random Forest\", X_train, X_test, y_train, y_test)\n",
        "models_results.append(rf_results)\n",
        "\n",
        "# Modelo 2: XGBoost\n",
        "print(\"\\nEntrenando XGBoost...\")\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "xgb_results = train_evaluate_model(xgb_model, \"XGBoost\", X_train, X_test, y_train, y_test)\n",
        "models_results.append(xgb_results)\n",
        "\n",
        "# Modelo 3: Regresión Logística\n",
        "print(\"\\nEntrenando Regresión Logística...\")\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_results = train_evaluate_model(lr_model, \"Regresión Logística\", X_train, X_test, y_train, y_test)\n",
        "models_results.append(lr_results)\n",
        "\n",
        "# Modelo 4: SVM\n",
        "print(\"\\nEntrenando SVM...\")\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_results = train_evaluate_model(svm_model, \"SVM\", X_train, X_test, y_train, y_test)\n",
        "models_results.append(svm_results)\n",
        "\n",
        "# Modelo 5: Árbol de Decisión\n",
        "print(\"\\nEntrenando Árbol de Decisión...\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_results = train_evaluate_model(dt_model, \"Árbol de Decisión\", X_train, X_test, y_train, y_test)\n",
        "models_results.append(dt_results)\n",
        "\n",
        "# Resumen de resultados\n",
        "print(\"\\n--- RESUMEN DE RESULTADOS ---\")\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "for result in models_results:\n",
        "    model_df = pd.DataFrame({\n",
        "        'Modelo': [result['model_name']],\n",
        "        'Accuracy': [result['accuracy']],\n",
        "        'Precision': [result['precision']],\n",
        "        'Recall': [result['recall']],\n",
        "        'F1-Score': [result['f1_score']],\n",
        "        'CV Mean': [result['cv_mean']],\n",
        "        'CV Std': [result['cv_std']],\n",
        "        'Train Accuracy': [result['train_accuracy']],\n",
        "        'Overfitting': [result['overfitting']]\n",
        "    })\n",
        "    results_df = pd.concat([results_df, model_df], ignore_index=True)\n",
        "\n",
        "print(\"\\nComparación de modelos:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Visualización de resultados\n",
        "plt.figure(figsize=(12, 8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EHSeYY-tSGqF",
        "outputId": "617b3480-792f-4dbb-8a5e-05700f4e5069"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando Random Forest...\n",
            "\n",
            "Entrenando XGBoost...\n",
            "\n",
            "Entrenando Regresión Logística...\n",
            "\n",
            "Entrenando SVM...\n",
            "\n",
            "Entrenando Árbol de Decisión...\n",
            "\n",
            "--- RESUMEN DE RESULTADOS ---\n",
            "\n",
            "Comparación de modelos:\n",
            "             Modelo  Accuracy  Precision   Recall  F1-Score  CV Mean   CV Std  Train Accuracy  Overfitting\n",
            "      Random Forest  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000        1.000000     0.000000\n",
            "            XGBoost  1.000000   1.000000 1.000000  1.000000 0.999996 0.000008        1.000000     0.000000\n",
            "Regresión Logística  0.999873   0.999873 0.999873  0.999873 0.999873 0.000040        0.999894     0.000021\n",
            "                SVM  0.999724   0.999724 0.999724  0.999724 0.999763 0.000078        0.999926     0.000201\n",
            "  Árbol de Decisión  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000        1.000000     0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de barras para accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x='Modelo', y='Accuracy', data=results_df)\n",
        "plt.title('Accuracy por Modelo')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Gráfico de barras para F1-Score\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x='Modelo', y='F1-Score', data=results_df)\n",
        "plt.title('F1-Score por Modelo')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Gráfico de barras para overfitting\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x='Modelo', y='Overfitting', data=results_df)\n",
        "plt.title('Overfitting por Modelo')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Gráfico de barras para validación cruzada\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x='Modelo', y='CV Mean', data=results_df)\n",
        "plt.title('Validación Cruzada por Modelo')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparacion_modelos.png')\n",
        "plt.close()\n",
        "\n",
        "# Identificar el mejor modelo\n",
        "best_model_idx = results_df['F1-Score'].idxmax()\n",
        "best_model_name = results_df.loc[best_model_idx, 'Modelo']\n",
        "print(f\"\\nEl mejor modelo basado en F1-Score es: {best_model_name}\")\n",
        "\n",
        "# Análisis de características importantes (para Random Forest)\n",
        "if 'Random Forest' in results_df['Modelo'].values:\n",
        "    print(\"\\n--- ANÁLISIS DE IMPORTANCIA DE CARACTERÍSTICAS (RANDOM FOREST) ---\")\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "\n",
        "    # Crear DataFrame para visualización\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 10 características más importantes:\")\n",
        "    print(importance_df.head(10).to_string(index=False))\n",
        "\n",
        "    # Visualización de importancia de características\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
        "    plt.title('Top 15 Características Más Importantes (Random Forest)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('importancia_caracteristicas.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eMOKk2vXibt",
        "outputId": "3c7921df-f796-49ff-b352-83f2dff09714"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El mejor modelo basado en F1-Score es: Random Forest\n",
            "\n",
            "--- ANÁLISIS DE IMPORTANCIA DE CARACTERÍSTICAS (RANDOM FOREST) ---\n",
            "\n",
            "Top 10 características más importantes:\n",
            "           Feature  Importance\n",
            "URLSimilarityIndex    0.181075\n",
            "   NoOfExternalRef    0.169265\n",
            "        LineOfCode    0.146585\n",
            "       NoOfSelfRef    0.108536\n",
            "         NoOfImage    0.084350\n",
            "            NoOfJS    0.072904\n",
            "           NoOfCSS    0.031598\n",
            "      HasSocialNet    0.031526\n",
            "  HasCopyrightInfo    0.025522\n",
            "           IsHTTPS    0.022940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eshilrpa7QVi",
        "outputId": "80929270-d26f-4dd6-dde0-0809a5dc2cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- OPTIMIZACIÓN DE HIPERPARÁMETROS ---\n",
            "\n",
            "Optimizando hiperparámetros para Random Forest...\n",
            "\n",
            "Mejores parámetros: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Mejor F1-Score: 1.0000\n",
            "\n",
            "Rendimiento del modelo optimizado:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "Accuracy en entrenamiento: 1.0000\n",
            "Accuracy en prueba: 1.0000\n",
            "Overfitting: 0.0000\n",
            "\n",
            "Resultados guardados en 'resultados_modelos.csv'\n",
            "\n",
            "--- ANÁLISIS COMPLETADO ---\n"
          ]
        }
      ],
      "source": [
        "# Optimización de hiperparámetros para el mejor modelo\n",
        "print(\"\\n--- OPTIMIZACIÓN DE HIPERPARÁMETROS ---\")\n",
        "\n",
        "if best_model_name == \"Random Forest\":\n",
        "    print(\"\\nOptimizando hiperparámetros para Random Forest...\")\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='f1_weighted')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"\\nMejores parámetros: {grid_search.best_params_}\")\n",
        "    print(f\"Mejor F1-Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Evaluar modelo optimizado\n",
        "    best_rf = grid_search.best_estimator_\n",
        "    y_pred_optimized = best_rf.predict(X_test)\n",
        "\n",
        "    print(\"\\nRendimiento del modelo optimizado:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_optimized):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred_optimized, average='weighted'):.4f}\")\n",
        "\n",
        "    # Verificar overfitting\n",
        "    train_acc_opt = accuracy_score(y_train, best_rf.predict(X_train))\n",
        "    test_acc_opt = accuracy_score(y_test, y_pred_optimized)\n",
        "    overfitting = train_acc_opt - test_acc_opt\n",
        "\n",
        "    print(f\"\\nAccuracy en entrenamiento: {train_acc_opt:.4f}\")\n",
        "    print(f\"Accuracy en prueba: {test_acc_opt:.4f}\")\n",
        "    print(f\"Overfitting: {overfitting:.4f}\")\n",
        "\n",
        "    if overfitting > 0.05:\n",
        "        print(\"\\n¡ADVERTENCIA! El modelo presenta un overfitting superior al 5%.\")\n",
        "        print(\"Recomendaciones para reducir el overfitting:\")\n",
        "        print(\"1. Aumentar la regularización\")\n",
        "        print(\"2. Reducir la complejidad del modelo\")\n",
        "        print(\"3. Utilizar técnicas de early stopping\")\n",
        "        print(\"4. Aplicar dropout o bagging\")\n",
        "\n",
        "elif best_model_name == \"XGBoost\":\n",
        "    print(\"\\nOptimizando hiperparámetros para XGBoost...\")\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.8, 0.9, 1.0]\n",
        "    }\n",
        "    grid_search = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid, cv=3, scoring='f1_weighted')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"\\nMejores parámetros: {grid_search.best_params_}\")\n",
        "    print(f\"Mejor F1-Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Evaluar modelo optimizado\n",
        "    best_xgb = grid_search.best_estimator_\n",
        "    y_pred_optimized = best_xgb.predict(X_test)\n",
        "\n",
        "    print(\"\\nRendimiento del modelo optimizado:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_optimized):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred_optimized, average='weighted'):.4f}\")\n",
        "\n",
        "    # Verificar overfitting\n",
        "    train_acc_opt = accuracy_score(y_train, best_xgb.predict(X_train))\n",
        "    test_acc_opt = accuracy_score(y_test, y_pred_optimized)\n",
        "    overfitting = train_acc_opt - test_acc_opt\n",
        "\n",
        "    print(f\"\\nAccuracy en entrenamiento: {train_acc_opt:.4f}\")\n",
        "    print(f\"Accuracy en prueba: {test_acc_opt:.4f}\")\n",
        "    print(f\"Overfitting: {overfitting:.4f}\")\n",
        "\n",
        "    if overfitting > 0.05:\n",
        "        print(\"\\n¡ADVERTENCIA! El modelo presenta un overfitting superior al 5%.\")\n",
        "        print(\"Recomendaciones para reducir el overfitting:\")\n",
        "        print(\"1. Aumentar la regularización (alpha, lambda)\")\n",
        "        print(\"2. Reducir la profundidad del árbol\")\n",
        "        print(\"3. Disminuir la tasa de aprendizaje\")\n",
        "        print(\"4. Aumentar el parámetro de subsample\")\n",
        "\n",
        "# Guardar resultados en un archivo\n",
        "results_df.to_csv('resultados_modelos.csv', index=False)\n",
        "print(\"\\nResultados guardados en 'resultados_modelos.csv'\")\n",
        "\n",
        "print(\"\\n--- ANÁLISIS COMPLETADO ---\")\n",
        "#else:\n",
        "    #print(f\"\\nNo se pudo identificar la columna objetivo en el dataset.\")"
      ]
    }
  ]
}